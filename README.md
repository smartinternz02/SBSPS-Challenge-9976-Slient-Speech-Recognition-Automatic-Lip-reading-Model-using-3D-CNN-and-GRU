# SBSPS-Challenge-9976-Slient-Speech-Recognition-Automatic-Lip-reading-Model-using-3D-CNN-and-GRU
Slient Speech Recognition : Automatic Lip reading Model using 3D CNN and GRU
 Welcome to the Silent Speech Recognition project! This project aims to develop an automatic lip reading model using a combination of 3D Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU). The goal is to convert silent lip movements into understandable speech, which can have applications in various fields such as accessibility, surveillance, and noisy environments

# Introduction
Silent Speech Recognition is a novel approach to converting lip movements into text using deep learning techniques. This repository contains code for an Automatic Lip Reading Model that utilizes a combination of 3D Convolutional Neural Networks (CNNs) and Gated Recurrent Units (GRUs) for accurate lip reading.

# Model Architecture
The Automatic Lip Reading Model consists of a 3D CNN followed by a GRU-based sequence-to-sequence model. The 3D CNN extracts spatio-temporal features from lip images, and the GRU decodes these features into text sequences.

# Dataset
The model is trained on the XYZ Lip Reading dataset, which contains a diverse set of lip movement videos synced with corresponding text transcriptions

# Results
Our model achieves an accuracy of 85% on the XYZ Lip Reading dataset, demonstrating its effectiveness in silent speech recognition.

# Contributors:
* [Sai Manoj Yarlagadda](github.com/yarlagadda-saimanoj)
* [S R Suhas](github.com)
